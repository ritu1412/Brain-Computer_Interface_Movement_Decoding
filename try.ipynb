{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_outer = StratifiedKFold(n_splits=6)\n",
    "lambdas = [0.01, 1, 100, 10000]\n",
    "def cross_validation(X,y):\n",
    "    outer_results = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    # First-level cross-validation\n",
    "    for i, (train_index, test_index) in enumerate(kf_outer.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Inner (second-level) cross-validation for regularization parameter tuning\n",
    "        kf_inner = StratifiedKFold(n_splits=5)\n",
    "        inner_results = []\n",
    "        \n",
    "        for lambda_val in lambdas:\n",
    "            lambda_scores = []\n",
    "            \n",
    "            for inner_train_index, inner_test_index in kf_inner.split(X_train, y_train):\n",
    "                X_inner_train, X_inner_test = X_train[inner_train_index], X_train[inner_test_index]\n",
    "                y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "                \n",
    "                # Train and evaluate the model on the inner fold\n",
    "                accuracy, _, _, _ = svm_classifier(X_inner_train, y_inner_train, X_inner_test, y_inner_test, lambda_val)\n",
    "                lambda_scores.append(accuracy)\n",
    "            \n",
    "            # Store the average accuracy for this lambda value\n",
    "            inner_results.append(np.mean(lambda_scores))\n",
    "        \n",
    "        # Select the best lambda value for this outer fold\n",
    "        best_lambda = lambdas[np.argmax(inner_results)]\n",
    "        \n",
    "        # Evaluate the model on the outer fold using the selected lambda value\n",
    "        accuracy, _, decision_statistics, _ = svm_classifier(X_train, y_train, X_test, y_test, best_lambda)\n",
    "\n",
    "        # Calculate ROC curve and area under the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, decision_statistics)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        \n",
    "        # Plot the ROC curve for the current fold\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        outer_results.append(accuracy)\n",
    "    \n",
    "    # Compute the mean and standard deviation of the TPRs for the cross-validated ROC curve\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    # Plot the cross-validated ROC curve\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=0.8)\n",
    "\n",
    "    # Plot the chance line\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=0.8)\n",
    "\n",
    "    # Final touches to the plot\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Overt Dataset Cross Validation')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute the average accuracy across all outer folds\n",
    "    average_accuracy = np.mean(outer_results)\n",
    "    print(f\"Average accuracy from two-level cross-validation: {average_accuracy}\")\n",
    "    #print best lambda value\n",
    "    print(f\"Best lambda value: {best_lambda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train on Imagined data and test on Overt data\n",
    "X_train = np.concatenate((Img_data_1.T, Img_data_2.T))\n",
    "y_train = np.array([0]*len(Img_data_1.T) + [1]*len(Img_data_2.T))\n",
    "X_test = np.concatenate((Overt_data_1.T, Overt_data_2.T))\n",
    "y_test = np.array([0]*len(Overt_data_1.T) + [1]*len(Overt_data_2.T))    \n",
    "accuracy, channel_weights, decision_statistics, num_support_vectors = svm_classifier(X_train, y_train, X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Number of Support Vectors:\", num_support_vectors)\n",
    "print(\"Decision Statistics for all test samples:\", decision_statistics)\n",
    "plot_roc_curve(y_test, decision_statistics)\n",
    "channel_weights_x = channel_weights[::2]\n",
    "channel_weights_y = channel_weights[1::2]\n",
    "show_channel_weights(channel_weights_x, channel_weights_y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
